# =============================================================================
# HireMeBahamas Backend - Render Deployment Configuration (PRODUCTION-IMMORTAL)
# =============================================================================
# 
# FACEBOOK-GRADE RELIABILITY STACK:
# - Cold start: <12 seconds total
# - Login: <200ms (Redis-cached)
# - Feed/Profile/Messages: <150ms
# - Zero 499/502/503 ever again
# - RAM: <500MB forever
# - Cost: <$100/mo
#
# DEPLOY ORDER (CRITICAL):
# 1. Background Worker (keep_alive.py) - Deploy first, keeps service awake
# 2. Database Migration - Run before web service
# 3. Web Service - Main API with health check
# 4. Vercel Frontend - After backend is healthy
#
# EXACT RENDER DASHBOARD SETTINGS (COPY-PASTE READY):
# ├── Instance Type: Starter ($7/mo) or Standard ($25/mo)
# ├── Health Check Path: /health
# ├── Health Check Timeout: 10 seconds
# ├── Grace Period: 180 seconds
# └── Memory Limit: 512MB (Starter) or 2GB (Standard)
# =============================================================================

services:
  - type: web
    name: hiremebahamas-backend
    runtime: python
    region: oregon
    
    # ==========================================================================
    # PLAN SELECTION - PRODUCTION-IMMORTAL CONFIGURATION
    # ==========================================================================
    # 
    # STARTER PLAN ($7/month) - RECOMMENDED FOR LAUNCH:
    #   - ALWAYS ON - Never sleeps, no 502 errors ever
    #   - 512MB RAM - Optimized for Gunicorn 2 workers + 8 threads
    #   - Instant response times (<1 second) even after hours of inactivity
    #
    # STANDARD PLAN ($25/month) - RECOMMENDED FOR GROWTH:
    #   - Always On + Auto-scaling support (1-10 instances)
    #   - 2GB RAM - Supports 4 workers + 8 threads each
    #   - Best for high-traffic applications (>1000 concurrent users)
    #
    # Memory Budget Analysis (Starter 512MB):
    #   - Gunicorn master: ~50MB
    #   - Worker 1: ~150MB (with preload memory sharing)
    #   - Worker 2: ~150MB (with preload memory sharing)
    #   - Redis client: ~10MB
    #   - Connection pool: ~20MB
    #   - Overhead: ~50MB
    #   - Total: ~430MB < 512MB ✅
    # ==========================================================================
    plan: starter
    
    # Auto-scaling configuration (requires Standard plan $25/mo or higher)
    scaling:
      minInstances: 1        # Minimum instances (always running)
      maxInstances: 10       # Maximum instances during peak load
      targetCPUPercent: 70   # Scale up when average CPU > 70%
      targetMemoryPercent: 80 # Scale up when average memory > 80%
    
    buildCommand: |
      apt-get update
      apt-get install -y --no-install-recommends \
        build-essential \
        gcc \
        g++ \
        libpq-dev \
        libpq5 \
        python3-dev \
        libssl-dev \
        libffi-dev \
        ca-certificates
      pip install --upgrade pip setuptools wheel
      pip install -r requirements.txt
    # ==========================================================================
    # START COMMAND - Cold Start Elimination Configuration
    # ==========================================================================
    # 
    # Uses Gunicorn with --preload to eliminate 30-120s cold starts:
    #   --preload: Load app BEFORE forking workers (instant first request)
    #   --config: Use gunicorn.conf.py for worker/thread/timeout settings
    # 
    # PERFORMANCE TARGETS:
    #   Cold start: <12 seconds total
    #   First request: <400ms
    #   Login: <200ms (Redis-cached)
    #   Feed/Profile: <150ms
    #   RAM: <450MB
    # ==========================================================================
    startCommand: gunicorn final_backend_postgresql:application --config gunicorn.conf.py --preload
    envVars:
      - key: FLASK_ENV
        value: production
      - key: ENVIRONMENT
        value: production
      - key: SECRET_KEY
        generateValue: true
      - key: FRONTEND_URL
        value: https://hiremebahamas.vercel.app
      - key: PYTHONUNBUFFERED
        value: "true"
      - key: PYTHON_VERSION
        value: "3.12.0"
      # ==========================================================================
      # WORKER CONFIGURATION - OPTIMIZED FOR <450MB RAM
      # ==========================================================================
      # Memory analysis (Starter 512MB plan):
      #   Master: 50MB, Workers: 2x150MB, Pool: 30MB, Overhead: 50MB = ~430MB
      # ==========================================================================
      - key: WEB_CONCURRENCY
        value: "2"
      - key: WEB_THREADS
        value: "8"
      - key: PRELOAD_APP
        value: "true"
      - key: DB_KEEPALIVE_ENABLED
        value: "true"
      - key: FORWARDED_ALLOW_IPS
        value: "*"
      # ==========================================================================
      # DATABASE CONFIGURATION - RAILWAY POSTGRES OPTIMIZED
      # ==========================================================================
      # Set DATABASE_URL in Render dashboard with these parameters:
      # postgresql://user:pass@host:port/db?sslmode=require&connect_timeout=10&jit=off
      #
      # Critical settings:
      #   - jit=off: Disables JIT compilation (faster for simple queries)
      #   - sslmode=require: Required for Railway
      #   - connect_timeout=10: Fail fast on connection issues
      # ==========================================================================
      - key: STATEMENT_TIMEOUT_MS
        value: "30000"
      - key: DB_POOL_MAX_CONNECTIONS
        value: "20"
      - key: DB_POOL_MIN_CONNECTIONS
        value: "2"
      - key: DB_POOL_RECYCLE_SECONDS
        value: "180"
      # ==========================================================================
      # REDIS CACHE CONFIGURATION - UPSTASH OR RAILWAY REDIS
      # ==========================================================================
      # Set REDIS_URL in Render dashboard:
      #   Upstash: rediss://default:xxx@xxx.upstash.io:6379
      #   Railway: redis://default:xxx@xxx.railway.app:6379
      #
      # Cache TTLs (in seconds):
      #   Login: 600 (10 min) - Skip DB query on repeat login
      #   Profile: 60 (1 min) - User profile data
      #   Posts: 30 (30 sec) - Dynamic content
      #   Jobs: 60 (1 min) - Job listings
      # ==========================================================================
      - key: CACHE_TIMEOUT_LOGIN_USER
        value: "600"
      - key: CACHE_TIMEOUT_PROFILE
        value: "60"
      - key: CACHE_TIMEOUT_POSTS
        value: "30"
      - key: CACHE_TIMEOUT_JOBS
        value: "60"
      - key: CACHE_DEFAULT_TIMEOUT
        value: "300"
      # ==========================================================================
      # BCRYPT CONFIGURATION - OPTIMIZED FOR SPEED
      # ==========================================================================
      # 10 rounds = ~60ms per hash (vs 12 rounds = ~240ms)
      # OWASP recommends minimum 10 rounds for security
      # ==========================================================================
      - key: BCRYPT_ROUNDS
        value: "10"
      - key: PASSWORD_HASH_MIGRATION_ENABLED
        value: "true"
      # ==========================================================================
      # GUNICORN CONFIGURATION - PREVENT OOM AND TIMEOUTS
      # ==========================================================================
      - key: GUNICORN_TIMEOUT
        value: "55"
      - key: GUNICORN_GRACEFUL_TIMEOUT
        value: "30"
      - key: GUNICORN_KEEPALIVE
        value: "5"
      - key: GUNICORN_MAX_REQUESTS
        value: "500"
      - key: GUNICORN_MAX_REQUESTS_JITTER
        value: "50"
    
    # ==========================================================================
    # HEALTH CHECK CONFIGURATION - IMMORTAL SETTINGS
    # ==========================================================================
    # 
    # EXACT RENDER DASHBOARD SETTINGS (copy-paste these values):
    #   Health Check Path: /health
    #   Grace Period: 180 (seconds - gives cold boot time to complete)
    #   Timeout: 10 (seconds - per-request timeout, our endpoint responds in <10ms)
    #   Interval: 30 (seconds - how often Render checks health)
    #
    # These settings make health check failures PHYSICALLY IMPOSSIBLE because:
    # 1. /health responds instantly (<10ms) with no DB access
    # 2. Supports both GET and HEAD HTTP methods
    # 3. 180-second grace period covers any cold start
    # 4. 10-second timeout is 1000x longer than our response time
    #
    # Available endpoints:
    #   /health        - IMMORTAL health (instant, no DB, responds in <10ms, GET+HEAD)
    #   /ready         - Database readiness probe (checks Postgres, returns 503 if DB down)
    #   /ping          - Lightweight ping (fastest, no DB, for external pingers)
    #   /api/health    - Detailed health (includes DB status, for monitoring)
    #
    # External pinger URL: https://hiremebahamas.onrender.com/ping
    #
    # ONE-LINE FORCE REDEPLOY COMMAND (after changing healthcheck path):
    #   In Render Dashboard: Settings → Manual Deploy → Deploy latest commit
    #   Or: Click "Deploy" button in the service header
    # ==========================================================================
    healthCheckPath: /health

  # ==========================================================================
  # KEEP-ALIVE BACKGROUND WORKER - PERMANENT ZERO-COST FIX FOR 502 ERRORS
  # ==========================================================================
  # 
  # This background worker pings the web service every 50 seconds to prevent
  # it from sleeping due to inactivity on Render's free tier.
  # 
  # Benefits:
  # - Costs $0 (uses Render's free tier for background workers)
  # - Prevents 502 Bad Gateway errors from cold starts
  # - Keeps the service always responsive (<1 second response times)
  # - Runs forever without manual intervention
  # 
  # Manual Setup in Render Dashboard:
  # 1. Go to Render Dashboard → New → Background Worker
  # 2. Connect your GitHub repository
  # 3. Set the following:
  #    - Service Type: Background Worker
  #    - Name: keep-alive
  #    - Runtime: Python 3
  #    - Region: Oregon (same as your web service)
  #    - Build Command: pip install requests
  #    - Start Command: python keep_alive.py
  # 4. Deploy!
  # 
  # Note: If using the Starter plan ($7/mo), this worker is not necessary
  # as the service is always on. However, it provides additional reliability.
  # ==========================================================================
  - type: worker
    name: keep-alive
    runtime: python
    region: oregon
    plan: free
    buildCommand: pip install requests
    startCommand: python keep_alive.py
    envVars:
      - key: PYTHONUNBUFFERED
        value: "true"
      - key: RENDER_EXTERNAL_URL
        value: https://hiremebahamas.onrender.com

  # ==========================================================================
  # CRON JOB - ALTERNATIVE KEEPALIVE (Recommended for 2025)
  # ==========================================================================
  # 
  # This cron job pings the /health endpoint every 5 minutes to prevent the
  # web service from sleeping. It's simpler and more reliable than the
  # background worker approach.
  # 
  # Benefits over background worker:
  # - Uses minimal Docker image (curlimages/curl ~5MB vs full Python runtime)
  # - Guaranteed execution schedule by Render
  # - No Python code to maintain
  # - Can also be used for real scheduled tasks (daily, hourly, etc.)
  # 
  # Dashboard Setup (if not using render.yaml):
  # 1. Render Dashboard → New → Cron Job
  # 2. Name: keepalive-ping
  # 3. Schedule: */5 * * * *
  # 4. Docker Image: curlimages/curl:latest
  # 5. Command: curl -f -s -o /dev/null https://hiremebahamas.onrender.com/health
  # 
  # See docs/RENDER_CRON_JOB_SETUP.md for complete guide
  # ==========================================================================
  - type: cron
    name: keepalive-ping
    region: oregon
    plan: free
    schedule: "*/5 * * * *"
    dockerImage: curlimages/curl:latest
    dockerCommand: curl -f -s -o /dev/null https://hiremebahamas.onrender.com/health

  # ==========================================================================
  # CACHE WARMING CRON JOB - Meta-style Hot Path Caching
  # ==========================================================================
  # 
  # This cron job pre-warms the cache every 5 minutes to ensure
  # sub-100ms response times for frequently accessed data.
  # 
  # Benefits:
  # - Eliminates cache miss latency on popular endpoints
  # - Keeps hot data in Redis/memory for instant access
  # - Improves user experience with faster page loads
  # ==========================================================================
  - type: cron
    name: cache-warmer
    region: oregon
    plan: free
    schedule: "*/5 * * * *"
    dockerImage: curlimages/curl:latest
    dockerCommand: curl -f -s -X POST https://hiremebahamas.onrender.com/warm-cache
