# =============================================================================
# HireMeBahamas Backend - Render Deployment Configuration
# =============================================================================
# 
# QUICK FIX FOR 502 ERRORS:
# The "starter" plan ($7/mo) keeps your service ALWAYS ON - no sleep, no 502s.
# For free tier: Use external pinger (UptimeRobot) to ping /ping every 5 min.
#
# See docs/RENDER_QUICK_START.md for step-by-step instructions
# See docs/RENDER_502_FIX_GUIDE.md for detailed troubleshooting
# See docs/HIGH_AVAILABILITY.md for advanced configuration
# =============================================================================

services:
  - type: web
    name: hiremebahamas-backend
    runtime: python
    region: oregon
    
    # ==========================================================================
    # PLAN SELECTION - Critical for 502 Prevention
    # ==========================================================================
    # 
    # FREE TIER ($0):
    #   - Sleeps after 15 minutes of inactivity
    #   - Causes 502 Bad Gateway on cold start (10-120+ seconds)
    #   - WORKAROUND: Use external pinger (UptimeRobot free tier)
    #
    # STARTER PLAN ($7/month) - RECOMMENDED:
    #   - ALWAYS ON - Never sleeps, no 502 errors ever
    #   - Instant response times (<1 second) even after hours of inactivity
    #   - Best for production job platforms
    #
    # STANDARD PLAN ($25/month):
    #   - Always On + Auto-scaling support
    #   - Best for high-traffic applications
    #
    # To change: Render Dashboard → Your Service → Settings → Instance Type
    # ==========================================================================
    plan: starter
    
    # Auto-scaling configuration (requires Standard plan $25/mo or higher)
    # Render automatically manages scaling based on these thresholds:
    # - When CPU exceeds targetCPUPercent, new instances are added
    # - When memory exceeds targetMemoryPercent, new instances are added
    # - Scaling down occurs after ~5 minutes of reduced load
    scaling:
      minInstances: 1        # Minimum instances (always running)
      maxInstances: 10       # Maximum instances during peak load
      targetCPUPercent: 70   # Scale up when average CPU > 70%
      targetMemoryPercent: 80 # Scale up when average memory > 80%
    
    buildCommand: |
      apt-get update
      apt-get install -y --no-install-recommends \
        build-essential \
        gcc \
        g++ \
        make \
        pkg-config \
        cmake \
        autoconf \
        automake \
        libtool \
        postgresql \
        postgresql-client \
        postgresql-client-common \
        postgresql-common \
        postgresql-contrib \
        libpq-dev \
        libpq5 \
        sqlite3 \
        libsqlite3-dev \
        libsqlite3-0 \
        python3-dev \
        python3-setuptools \
        python3-wheel \
        libssl-dev \
        libffi-dev \
        ca-certificates \
        libjpeg-dev \
        libpng-dev \
        libtiff-dev \
        libwebp-dev \
        zlib1g-dev \
        libfreetype6-dev \
        liblcms2-dev \
        libevent-dev \
        libxml2-dev \
        libxslt1-dev \
        libreadline-dev \
        libbz2-dev \
        libncurses5-dev \
        curl \
        wget \
        git
      pip install --upgrade pip setuptools wheel
      pip install -r requirements.txt
    # ==========================================================================
    # START COMMAND - BULLETPROOF CONFIGURATION (OOM + Timeout Prevention)
    # ==========================================================================
    # 
    # This configuration ELIMINATES two fatal errors permanently:
    # 1. "timeout expired" - Prevented by --timeout 120 + pool_pre_ping
    # 2. "Worker sent SIGKILL (OOM)" - Prevented by 1 worker + --max-requests
    # 
    # COPY-PASTE THIS EXACT COMMAND INTO RENDER DASHBOARD:
    # gunicorn backend.app.main:app -k uvicorn.workers.UvicornWorker --workers 1 --max-requests 1000 --max-requests-jitter 100 --timeout 120 --keep-alive 5 --bind 0.0.0.0:$PORT
    #
    # WHY EACH FLAG:
    # --workers 1:            Uses <400MB RAM (vs 2+ workers = 600MB+ = SIGKILL)
    # --max-requests 1000:    Restart worker after 1000 requests (prevents memory leaks)
    # --max-requests-jitter:  Randomize restart to prevent cold start at exact same time
    # --timeout 120:          Worker timeout for long operations (login, uploads)
    # --keep-alive 5:         Close idle connections quickly to free memory
    # -k uvicorn.workers:     Use Uvicorn for async FastAPI support
    #
    # RECOMMENDED RENDER INSTANCE: 1024 MB (Starter $7/mo is sufficient with this config)
    # ==========================================================================
    startCommand: gunicorn backend.app.main:app -k uvicorn.workers.UvicornWorker --workers 1 --max-requests 1000 --max-requests-jitter 100 --timeout 120 --keep-alive 5 --bind 0.0.0.0:$PORT
    envVars:
      - key: ENVIRONMENT
        value: production
      - key: SECRET_KEY
        generateValue: true
      - key: FRONTEND_URL
        value: https://hiremebahamas.vercel.app
      - key: PYTHONUNBUFFERED
        value: "true"
      - key: PYTHON_VERSION
        value: "3.12.0"
      # ==========================================================================
      # DATABASE POOL CONFIGURATION (CRITICAL FOR OOM PREVENTION)
      # ==========================================================================
      # These values are tuned for Render 512MB-1GB instances
      # Each PostgreSQL connection uses ~20-50MB RAM
      # pool_size=2 + max_overflow=3 = max 5 connections = ~150MB for DB
      # ==========================================================================
      - key: DB_POOL_SIZE
        value: "2"
      - key: DB_POOL_MAX_OVERFLOW
        value: "3"
      - key: DB_POOL_TIMEOUT
        value: "20"
      - key: POOL_RECYCLE_SECONDS
        value: "60"
      - key: STATEMENT_TIMEOUT_SECONDS
        value: "25"
      # Trust Render's load balancer for X-Forwarded-* headers
      - key: FORWARDED_ALLOW_IPS
        value: "*"
      # ==========================================================================
      # DATABASE_URL CONFIGURATION (SET THIS IN RENDER DASHBOARD)
      # ==========================================================================
      # Copy your Railway PostgreSQL URL and ensure it has these parameters:
      # 
      # postgresql+asyncpg://postgres:<password>@<host>:<port>/<db>?sslmode=require&connect_timeout=20&options=-c%20jit=off
      #
      # REQUIRED PARAMETERS:
      # - sslmode=require:     Force SSL for Railway connections
      # - connect_timeout=20:  Prevent timeout during cold starts  
      # - options=-c jit=off:  Disable JIT to save ~100MB RAM
      # ==========================================================================
    
    # ==========================================================================
    # HEALTH CHECK CONFIGURATION - IMMORTAL SETTINGS
    # ==========================================================================
    # 
    # EXACT RENDER DASHBOARD SETTINGS (copy-paste these values):
    #   Health Check Path: /health
    #   Grace Period: 180 (seconds - gives cold boot time to complete)
    #   Timeout: 10 (seconds - per-request timeout, our endpoint responds in <10ms)
    #   Interval: 30 (seconds - how often Render checks health)
    #
    # These settings make health check failures PHYSICALLY IMPOSSIBLE because:
    # 1. /health responds instantly (<10ms) with no DB access
    # 2. Supports both GET and HEAD HTTP methods
    # 3. 180-second grace period covers any cold start
    # 4. 10-second timeout is 1000x longer than our response time
    #
    # Available endpoints:
    #   /health        - IMMORTAL health (instant, no DB, responds in <10ms, GET+HEAD)
    #   /ready         - Database readiness probe (checks Postgres, returns 503 if DB down)
    #   /ping          - Lightweight ping (fastest, no DB, for external pingers)
    #   /api/health    - Detailed health (includes DB status, for monitoring)
    #
    # External pinger URL: https://hiremebahamas.onrender.com/ping
    #
    # ONE-LINE FORCE REDEPLOY COMMAND (after changing healthcheck path):
    #   In Render Dashboard: Settings → Manual Deploy → Deploy latest commit
    #   Or: Click "Deploy" button in the service header
    # ==========================================================================
    healthCheckPath: /health

  # ==========================================================================
  # KEEP-ALIVE BACKGROUND WORKER - PERMANENT ZERO-COST FIX FOR 502 ERRORS
  # ==========================================================================
  # 
  # This background worker pings the web service every 50 seconds to prevent
  # it from sleeping due to inactivity on Render's free tier.
  # 
  # Benefits:
  # - Costs $0 (uses Render's free tier for background workers)
  # - Prevents 502 Bad Gateway errors from cold starts
  # - Keeps the service always responsive (<1 second response times)
  # - Runs forever without manual intervention
  # 
  # Manual Setup in Render Dashboard:
  # 1. Go to Render Dashboard → New → Background Worker
  # 2. Connect your GitHub repository
  # 3. Set the following:
  #    - Service Type: Background Worker
  #    - Name: keep-alive
  #    - Runtime: Python 3
  #    - Region: Oregon (same as your web service)
  #    - Build Command: pip install requests
  #    - Start Command: python keep_alive.py
  # 4. Deploy!
  # 
  # Note: If using the Starter plan ($7/mo), this worker is not necessary
  # as the service is always on. However, it provides additional reliability.
  # ==========================================================================
  - type: worker
    name: keep-alive
    runtime: python
    region: oregon
    plan: free
    buildCommand: pip install requests
    startCommand: python keep_alive.py
    envVars:
      - key: PYTHONUNBUFFERED
        value: "true"
      - key: RENDER_EXTERNAL_URL
        value: https://hiremebahamas.onrender.com

  # ==========================================================================
  # CRON JOB - ALTERNATIVE KEEPALIVE (Recommended for 2025)
  # ==========================================================================
  # 
  # This cron job pings the /health endpoint every 5 minutes to prevent the
  # web service from sleeping. It's simpler and more reliable than the
  # background worker approach.
  # 
  # Benefits over background worker:
  # - Uses minimal Docker image (curlimages/curl ~5MB vs full Python runtime)
  # - Guaranteed execution schedule by Render
  # - No Python code to maintain
  # - Can also be used for real scheduled tasks (daily, hourly, etc.)
  # 
  # Dashboard Setup (if not using render.yaml):
  # 1. Render Dashboard → New → Cron Job
  # 2. Name: keepalive-ping
  # 3. Schedule: */5 * * * *
  # 4. Docker Image: curlimages/curl:latest
  # 5. Command: curl -f -s -o /dev/null https://hiremebahamas.onrender.com/health
  # 
  # See docs/RENDER_CRON_JOB_SETUP.md for complete guide
  # ==========================================================================
  - type: cron
    name: keepalive-ping
    region: oregon
    plan: free
    schedule: "*/5 * * * *"
    dockerImage: curlimages/curl:latest
    dockerCommand: curl -f -s -o /dev/null https://hiremebahamas.onrender.com/health

  # ==========================================================================
  # CACHE WARMING CRON JOB - Meta-style Hot Path Caching
  # ==========================================================================
  # 
  # This cron job pre-warms the cache every 5 minutes to ensure
  # sub-100ms response times for frequently accessed data.
  # 
  # Benefits:
  # - Eliminates cache miss latency on popular endpoints
  # - Keeps hot data in Redis/memory for instant access
  # - Improves user experience with faster page loads
  # ==========================================================================
  - type: cron
    name: cache-warmer
    region: oregon
    plan: free
    schedule: "*/5 * * * *"
    dockerImage: curlimages/curl:latest
    dockerCommand: curl -f -s -X POST https://hiremebahamas.onrender.com/warm-cache
