# ============================================================================
# NGINX Load Balancer Configuration - Production Scaling
# ============================================================================
#
# This configuration distributes traffic across multiple FastAPI backend pods
# for horizontal scaling to 1M+ users.
#
# Production: Render/Railway handles load balancing automatically.
# This file is for local testing and understanding the architecture.
#
# ============================================================================

# Worker processes (auto-detect CPU cores)
worker_processes auto;

# Maximum number of open files per worker
worker_rlimit_nofile 65535;

events {
    # Maximum connections per worker
    worker_connections 4096;
    
    # Use efficient event handling
    use epoll;
    
    # Accept multiple connections at once
    multi_accept on;
}

http {
    # ========================================================================
    # BASIC SETTINGS
    # ========================================================================
    
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';
    
    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;
    
    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    keepalive_requests 100;
    
    # Client settings
    client_max_body_size 50M;
    client_body_buffer_size 128k;
    client_header_buffer_size 1k;
    large_client_header_buffers 4 8k;
    
    # Timeouts
    client_body_timeout 30s;
    client_header_timeout 30s;
    send_timeout 30s;
    
    # Compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss 
               application/rss+xml font/truetype font/opentype 
               application/vnd.ms-fontobject image/svg+xml;
    gzip_disable "msie6";
    
    # ========================================================================
    # UPSTREAM BACKEND PODS
    # Round-robin load balancing across FastAPI pods
    # ========================================================================
    
    upstream backend_pods {
        # Load balancing algorithm (default: round-robin)
        # Options: round-robin, least_conn, ip_hash, least_time
        least_conn;  # Send to pod with fewest active connections
        
        # Backend pod 1
        server backend-1:8000 max_fails=3 fail_timeout=30s weight=1;
        
        # Backend pod 2
        server backend-2:8000 max_fails=3 fail_timeout=30s weight=1;
        
        # Backend pod 3
        server backend-3:8000 max_fails=3 fail_timeout=30s weight=1;
        
        # Keepalive connections to backends (reuse connections)
        keepalive 32;
        keepalive_requests 100;
        keepalive_timeout 60s;
    }
    
    # ========================================================================
    # HEALTH CHECK UPSTREAM
    # Dedicated upstream for health checks (don't count toward stats)
    # ========================================================================
    
    upstream backend_health {
        server backend-1:8000;
        keepalive 2;
    }
    
    # ========================================================================
    # HTTP SERVER (Redirect to HTTPS)
    # ========================================================================
    
    server {
        listen 80 default_server;
        listen [::]:80 default_server;
        server_name _;
        
        # Health check endpoint (allow HTTP for load balancer health checks)
        location /health {
            access_log off;
            proxy_pass http://backend_health/health;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }
        
        # Redirect all other traffic to HTTPS
        location / {
            return 301 https://$host$request_uri;
        }
    }
    
    # ========================================================================
    # HTTPS SERVER (Main Application)
    # ========================================================================
    
    server {
        listen 443 ssl http2 default_server;
        listen [::]:443 ssl http2 default_server;
        server_name _;
        
        # SSL Configuration (update paths in production)
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        
        # SSL Security Settings
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        
        # Security Headers
        add_header X-Frame-Options "DENY" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;
        add_header Permissions-Policy "camera=(), microphone=(), geolocation=(self)" always;
        
        # ====================================================================
        # API ENDPOINTS (Proxy to Backend Pods)
        # ====================================================================
        
        location /api/ {
            # Proxy to backend pods (load balanced)
            proxy_pass http://backend_pods;
            
            # HTTP version and connection reuse
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            
            # Timeouts
            proxy_connect_timeout 30s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # Buffering
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            # Error handling
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 30s;
            
            # No caching for API responses
            add_header Cache-Control "no-store, no-cache, must-revalidate" always;
        }
        
        # ====================================================================
        # WEBSOCKET CONNECTIONS (Real-time)
        # ====================================================================
        
        location /ws/ {
            proxy_pass http://backend_pods;
            
            # WebSocket headers
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            
            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Long timeouts for WebSocket
            proxy_connect_timeout 7d;
            proxy_send_timeout 7d;
            proxy_read_timeout 7d;
            
            # No buffering for WebSocket
            proxy_buffering off;
        }
        
        # ====================================================================
        # HEALTH CHECKS (No Load Balancing)
        # ====================================================================
        
        location /health {
            access_log off;
            proxy_pass http://backend_health/health;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            # Fast timeout for health checks
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }
        
        location /ready {
            access_log off;
            proxy_pass http://backend_health/ready;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }
        
        # ====================================================================
        # STATIC FILES (If serving from NGINX)
        # Production: Use Vercel Edge CDN or Cloudflare R2 instead
        # ====================================================================
        
        location /static/ {
            alias /app/static/;
            
            # Caching
            expires 1y;
            add_header Cache-Control "public, immutable";
            
            # Compression
            gzip_static on;
        }
        
        location /media/ {
            alias /app/media/;
            
            # Caching
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
        
        # ====================================================================
        # MONITORING & METRICS
        # ====================================================================
        
        # NGINX status (for monitoring)
        location /nginx-status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
        }
    }
    
    # ========================================================================
    # BACKEND MONITORING SERVER (Internal Only)
    # ========================================================================
    
    server {
        listen 8081;
        server_name _;
        
        # NGINX status endpoint
        location /nginx-health {
            stub_status on;
            access_log off;
        }
        
        # Prometheus metrics (if using nginx-prometheus-exporter)
        location /metrics {
            access_log off;
            # Proxy to nginx-prometheus-exporter if running
            # proxy_pass http://localhost:9113/metrics;
        }
    }
}
