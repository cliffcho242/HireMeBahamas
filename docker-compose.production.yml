# ============================================================================
# HireMeBahamas - PRODUCTION SCALING Docker Compose Configuration
# ============================================================================
#
# ðŸš€ PRODUCTION DEPLOYMENT - Scale to 1M+ Users
#
# This configuration demonstrates the scaling architecture for HireMeBahamas.
# In production, use managed services (Render, Railway, Neon, Upstash, R2).
#
# ðŸ“– Documentation:
#    - Scaling blueprint: SCALE_TO_1M_USERS_BLUEPRINT.md
#    - Backend pattern: BACKEND_SCALING_PATTERN.md
#    - Monetization: MONETIZATION_STRATEGY.md
#
# ðŸ’» Usage:
#    Development test: docker-compose -f docker-compose.production.yml up
#    Production: Use managed services (see documentation)
#
# âš ï¸  WARNING: This is for LOCAL TESTING only. Production should use:
#    - Vercel Edge CDN (frontend)
#    - Render autoscaling (backend)
#    - Neon PostgreSQL (database with replicas)
#    - Upstash Redis (serverless cache)
#    - Cloudflare R2 (file storage)
#
# ============================================================================

version: '3.8'

services:
  # =========================================================================
  # NGINX LOAD BALANCER
  # Distributes traffic across multiple backend pods
  # Production: Handled by Render/Railway automatically
  # =========================================================================
  nginx-lb:
    image: nginx:1.25-alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx-production.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend-1
      - backend-2
      - backend-3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # =========================================================================
  # BACKEND PODS (FastAPI + Gunicorn)
  # Multiple pods for horizontal scaling
  # Production: Render/Railway auto-scales 2-10 pods
  # =========================================================================
  backend-1:
    build:
      context: ./backend
      dockerfile: Dockerfile.production
    environment:
      # Database (Primary for writes)
      DATABASE_URL: postgresql+asyncpg://user:pass@postgres-primary:5432/hiremebahamas?ssl=require
      # Database Read Replicas (for reads)
      DATABASE_READ_REPLICA_1: postgresql+asyncpg://user:pass@postgres-replica-1:5432/hiremebahamas?ssl=require
      DATABASE_READ_REPLICA_2: postgresql+asyncpg://user:pass@postgres-replica-2:5432/hiremebahamas?ssl=require
      # Redis Cache
      REDIS_URL: redis://redis:6379
      # Application Config
      ENVIRONMENT: production
      SECRET_KEY: ${SECRET_KEY}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      # Worker Config
      WEB_CONCURRENCY: 4
      WEB_THREADS: 4
      # File Storage (Cloudflare R2)
      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_ACCESS_KEY: ${R2_ACCESS_KEY}
      R2_SECRET_KEY: ${R2_SECRET_KEY}
      R2_BUCKET: hiremebahamas-uploads
      # Monitoring
      INSTANCE_ID: backend-1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  backend-2:
    build:
      context: ./backend
      dockerfile: Dockerfile.production
    environment:
      DATABASE_URL: postgresql+asyncpg://user:pass@postgres-primary:5432/hiremebahamas?ssl=require
      DATABASE_READ_REPLICA_1: postgresql+asyncpg://user:pass@postgres-replica-1:5432/hiremebahamas?ssl=require
      DATABASE_READ_REPLICA_2: postgresql+asyncpg://user:pass@postgres-replica-2:5432/hiremebahamas?ssl=require
      REDIS_URL: redis://redis:6379
      ENVIRONMENT: production
      SECRET_KEY: ${SECRET_KEY}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      WEB_CONCURRENCY: 4
      WEB_THREADS: 4
      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_ACCESS_KEY: ${R2_ACCESS_KEY}
      R2_SECRET_KEY: ${R2_SECRET_KEY}
      R2_BUCKET: hiremebahamas-uploads
      INSTANCE_ID: backend-2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  backend-3:
    build:
      context: ./backend
      dockerfile: Dockerfile.production
    environment:
      DATABASE_URL: postgresql+asyncpg://user:pass@postgres-primary:5432/hiremebahamas?ssl=require
      DATABASE_READ_REPLICA_1: postgresql+asyncpg://user:pass@postgres-replica-1:5432/hiremebahamas?ssl=require
      DATABASE_READ_REPLICA_2: postgresql+asyncpg://user:pass@postgres-replica-2:5432/hiremebahamas?ssl=require
      REDIS_URL: redis://redis:6379
      ENVIRONMENT: production
      SECRET_KEY: ${SECRET_KEY}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      WEB_CONCURRENCY: 4
      WEB_THREADS: 4
      R2_ACCOUNT_ID: ${R2_ACCOUNT_ID}
      R2_ACCESS_KEY: ${R2_ACCESS_KEY}
      R2_SECRET_KEY: ${R2_SECRET_KEY}
      R2_BUCKET: hiremebahamas-uploads
      INSTANCE_ID: backend-3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # =========================================================================
  # POSTGRESQL PRIMARY (Write Operations)
  # Production: Neon PostgreSQL serverless
  # =========================================================================
  postgres-primary:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: hiremebahamas
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    volumes:
      - postgres-primary-data:/var/lib/postgresql/data
    command: >
      postgres
      -c shared_buffers=512MB
      -c max_connections=200
      -c effective_cache_size=1GB
      -c maintenance_work_mem=128MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=5MB
      -c min_wal_size=2GB
      -c max_wal_size=8GB
      -c max_worker_processes=4
      -c max_parallel_workers_per_gather=2
      -c max_parallel_workers=4
      -c wal_level=replica
      -c max_wal_senders=3
      -c wal_keep_size=1GB
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  # =========================================================================
  # POSTGRESQL READ REPLICAS (Read Operations)
  # Production: Neon PostgreSQL read replicas (auto-managed)
  # =========================================================================
  postgres-replica-1:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: hiremebahamas
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres-replica-1-data:/var/lib/postgresql/data
    command: >
      bash -c "
      until pg_basebackup -h postgres-primary -D /var/lib/postgresql/data/pgdata -U ${POSTGRES_USER} -v -P; do
        echo 'Waiting for primary to be ready...'
        sleep 5
      done
      echo 'standby_mode = on' > /var/lib/postgresql/data/pgdata/recovery.conf
      echo 'primary_conninfo = ''host=postgres-primary port=5432 user=${POSTGRES_USER} password=${POSTGRES_PASSWORD}''' >> /var/lib/postgresql/data/pgdata/recovery.conf
      postgres
      "
    depends_on:
      - postgres-primary
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  postgres-replica-2:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: hiremebahamas
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
      PGPASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres-replica-2-data:/var/lib/postgresql/data
    command: >
      bash -c "
      until pg_basebackup -h postgres-primary -D /var/lib/postgresql/data/pgdata -U ${POSTGRES_USER} -v -P; do
        echo 'Waiting for primary to be ready...'
        sleep 5
      done
      echo 'standby_mode = on' > /var/lib/postgresql/data/pgdata/recovery.conf
      echo 'primary_conninfo = ''host=postgres-primary port=5432 user=${POSTGRES_USER} password=${POSTGRES_PASSWORD}''' >> /var/lib/postgresql/data/pgdata/recovery.conf
      postgres
      "
    depends_on:
      - postgres-primary
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  # =========================================================================
  # REDIS CACHE (Sessions, Feeds, Pub/Sub)
  # Production: Upstash Redis serverless
  # =========================================================================
  redis:
    image: redis:7-alpine
    command: >
      redis-server
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save ""
      --appendonly no
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # =========================================================================
  # MONITORING & OBSERVABILITY (Optional)
  # Production: Use DataDog, New Relic, or similar
  # =========================================================================
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    networks:
      - app-network
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    ports:
      - "3001:3000"
    depends_on:
      - prometheus
    networks:
      - app-network
    profiles:
      - monitoring

networks:
  app-network:
    driver: bridge

volumes:
  postgres-primary-data:
  postgres-replica-1-data:
  postgres-replica-2-data:
  redis-data:
  prometheus-data:
  grafana-data:
