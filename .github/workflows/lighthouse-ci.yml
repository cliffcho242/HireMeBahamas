name: Lighthouse CI - Performance Monitoring

on:
  pull_request:
    branches:
      - main
  push:
    branches:
      - main
  workflow_dispatch:

# Prevent concurrent runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lighthouse:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: ./frontend
        run: |
          # Add retry logic for npm ci
          for i in 1 2 3; do
            if npm ci; then
              echo "‚úÖ Dependencies installed successfully"
              break
            else
              if [ $i -eq 3 ]; then
                echo "::error::‚ùå Failed to install dependencies after 3 attempts"
                exit 1
              fi
              echo "‚ö†Ô∏è Attempt $i failed, retrying..."
              sleep 5
            fi
          done

      - name: Build frontend for production
        working-directory: ./frontend
        run: npm run build
        env:
          # Use production-like settings
          NODE_ENV: production
          VITE_API_URL: https://hiremebahamas.onrender.com

      - name: Bundle size analysis
        working-directory: ./frontend
        run: |
          echo "## üì¶ Bundle Size Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f "dist/bundle-report.json" ]; then
            # Extract and display bundle sizes
            echo "Bundle analysis completed successfully" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "See detailed output in the build logs above." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Install Lighthouse CI
        run: npm install -g @lhci/cli@0.13.x

      - name: Run Lighthouse CI
        run: |
          lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Upload Lighthouse reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-reports
          path: lighthouse-reports/
          retention-days: 30

      - name: Check performance scores
        if: always()
        run: |
          echo "## üéØ Lighthouse Performance Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Parse the latest manifest.json for scores
          if [ -f "lighthouse-reports/manifest.json" ]; then
            echo "‚úÖ Lighthouse CI completed successfully" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Try to extract actual scores from the manifest
            if command -v jq &> /dev/null; then
              # Use jq to parse scores if available
              PERF_SCORE=$(jq -r '.[0].summary.performance // "N/A"' lighthouse-reports/manifest.json 2>/dev/null || echo "N/A")
              A11Y_SCORE=$(jq -r '.[0].summary.accessibility // "N/A"' lighthouse-reports/manifest.json 2>/dev/null || echo "N/A")
              BP_SCORE=$(jq -r '.[0].summary."best-practices" // "N/A"' lighthouse-reports/manifest.json 2>/dev/null || echo "N/A")
              SEO_SCORE=$(jq -r '.[0].summary.seo // "N/A"' lighthouse-reports/manifest.json 2>/dev/null || echo "N/A")
              
              echo "**Scores:**" >> $GITHUB_STEP_SUMMARY
              echo "- Performance: ${PERF_SCORE}" >> $GITHUB_STEP_SUMMARY
              echo "- Accessibility: ${A11Y_SCORE}" >> $GITHUB_STEP_SUMMARY
              echo "- Best Practices: ${BP_SCORE}" >> $GITHUB_STEP_SUMMARY
              echo "- SEO: ${SEO_SCORE}" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "**Performance targets:**" >> $GITHUB_STEP_SUMMARY
            echo "- üéØ Target: 90+ for all categories" >> $GITHUB_STEP_SUMMARY
            echo "- ‚ö° First Contentful Paint: < 1.8s" >> $GITHUB_STEP_SUMMARY
            echo "- üñºÔ∏è Largest Contentful Paint: < 2.5s" >> $GITHUB_STEP_SUMMARY
            echo "- üìè Cumulative Layout Shift: < 0.1" >> $GITHUB_STEP_SUMMARY
            echo "- üöÄ Total Blocking Time: < 200ms" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "üìä Detailed reports are available in the artifacts." >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No Lighthouse reports found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment PR with Lighthouse results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Check if manifest exists
            const manifestPath = path.join(process.cwd(), 'lighthouse-reports', 'manifest.json');
            if (!fs.existsSync(manifestPath)) {
              console.log('No manifest file found, skipping PR comment');
              return;
            }
            
            // Read manifest
            const manifest = JSON.parse(fs.readFileSync(manifestPath, 'utf8'));
            
            // Helper to format score with emoji
            const formatScore = (score) => {
              if (score === null || score === undefined) return 'N/A';
              const percentage = Math.round(score * 100);
              const emoji = percentage >= 90 ? '‚úÖ' : percentage >= 50 ? '‚ö†Ô∏è' : '‚ùå';
              return `${emoji} ${percentage}`;
            };
            
            // Build comment
            let comment = '## üéØ Lighthouse CI Performance Report\n\n';
            
            // Try to extract scores from first result
            if (manifest.length > 0 && manifest[0].summary) {
              const summary = manifest[0].summary;
              
              comment += '| Category | Score | Target |\n';
              comment += '|----------|-------|--------|\n';
              comment += `| Performance | ${formatScore(summary.performance)} | 90+ |\n`;
              comment += `| Accessibility | ${formatScore(summary.accessibility)} | 90+ |\n`;
              comment += `| Best Practices | ${formatScore(summary['best-practices'])} | 90+ |\n`;
              comment += `| SEO | ${formatScore(summary.seo)} | 90+ |\n`;
              comment += '\n';
            }
            
            // Add performance budget details
            comment += '### üìè Performance Budget\n\n';
            comment += '| Metric | Target |\n';
            comment += '|--------|--------|\n';
            comment += '| First Contentful Paint | < 1.8s |\n';
            comment += '| Largest Contentful Paint | < 2.5s |\n';
            comment += '| Cumulative Layout Shift | < 0.1 |\n';
            comment += '| Total Blocking Time | < 200ms |\n';
            comment += '| Speed Index | < 3.4s |\n';
            comment += '\n';
            
            // Add bundle size info if available
            const bundleReportPath = path.join(process.cwd(), 'frontend', 'dist', 'bundle-report.json');
            if (fs.existsSync(bundleReportPath)) {
              const bundleReport = JSON.parse(fs.readFileSync(bundleReportPath, 'utf8'));
              comment += '### üì¶ Bundle Size\n\n';
              comment += `- Total JS: ${bundleReport.stats.totalJS.toFixed(2)} KB\n`;
              comment += `- Total CSS: ${bundleReport.stats.totalCSS.toFixed(2)} KB\n`;
              
              if (bundleReport.warnings.length > 0) {
                comment += '\n‚ö†Ô∏è **Warnings:**\n';
                bundleReport.warnings.forEach(w => {
                  comment += `- ${w}\n`;
                });
              }
              comment += '\n';
            }
            
            comment += 'üìä View detailed reports in the [workflow artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).\n';
            
            // Post comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });

  # Monitor performance with Sentry
  sentry-performance:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    needs: lighthouse
    permissions:
      contents: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create Sentry release
        uses: getsentry/action-release@v1
        if: env.SENTRY_AUTH_TOKEN != ''
        env:
          SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}
          SENTRY_ORG: ${{ secrets.SENTRY_ORG }}
          SENTRY_PROJECT: ${{ secrets.SENTRY_PROJECT }}
        with:
          environment: production
          version: ${{ github.sha }}
          
      - name: Upload source maps to Sentry
        if: env.SENTRY_AUTH_TOKEN != ''
        env:
          SENTRY_AUTH_TOKEN: ${{ secrets.SENTRY_AUTH_TOKEN }}
          SENTRY_ORG: ${{ secrets.SENTRY_ORG }}
          SENTRY_PROJECT: ${{ secrets.SENTRY_PROJECT }}
        run: |
          echo "Sentry source maps upload would happen here"
          echo "This requires building with source maps and using @sentry/cli"
